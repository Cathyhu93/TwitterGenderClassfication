{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_curve, pairwise\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>created</th>\n",
       "      <th>...</th>\n",
       "      <th>profileimage</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12/5/13 1:48</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
       "      <td>0</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110964</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>main; @Kan1shk3</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/1/12 13:51</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7471</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/28/14 11:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
       "      <td>1</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5617</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>clcncl</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6/11/09 22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
       "      <td>0</td>\n",
       "      <td>C0DEED</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1693</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/16/14 13:23</td>\n",
       "      <td>...</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31462</td>\n",
       "      <td>10/26/15 12:40</td>\n",
       "      <td>6.587300e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  815719226    False   finalized                   3    10/26/15 23:24   \n",
       "1  815719227    False   finalized                   3    10/26/15 23:30   \n",
       "2  815719228    False   finalized                   3    10/26/15 23:33   \n",
       "3  815719229    False   finalized                   3    10/26/15 23:10   \n",
       "4  815719230    False   finalized                   3     10/27/15 1:15   \n",
       "\n",
       "   gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
       "0    male             1.0000        yes                    1.0   \n",
       "1    male             1.0000        yes                    1.0   \n",
       "2    male             0.6625        yes                    1.0   \n",
       "3    male             1.0000        yes                    1.0   \n",
       "4  female             1.0000        yes                    1.0   \n",
       "\n",
       "          created             ...              \\\n",
       "0    12/5/13 1:48             ...               \n",
       "1   10/1/12 13:51             ...               \n",
       "2  11/28/14 11:30             ...               \n",
       "3   6/11/09 22:39             ...               \n",
       "4   4/16/14 13:23             ...               \n",
       "\n",
       "                                        profileimage  retweet_count  \\\n",
       "0  https://pbs.twimg.com/profile_images/414342229...              0   \n",
       "1  https://pbs.twimg.com/profile_images/539604221...              0   \n",
       "2  https://pbs.twimg.com/profile_images/657330418...              1   \n",
       "3  https://pbs.twimg.com/profile_images/259703936...              0   \n",
       "4  https://pbs.twimg.com/profile_images/564094871...              0   \n",
       "\n",
       "  sidebar_color                                               text  \\\n",
       "0        FFFFFF  Robbie E Responds To Critics After Win Against...   \n",
       "1        C0DEED  ÛÏIt felt like they were my friends and I was...   \n",
       "2        C0DEED  i absolutely adore when louis starts the songs...   \n",
       "3        C0DEED  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "4             0  Watching Neighbours on Sky+ catching up with t...   \n",
       "\n",
       "  tweet_coord tweet_count   tweet_created      tweet_id   tweet_location  \\\n",
       "0         NaN      110964  10/26/15 12:40  6.587300e+17  main; @Kan1shk3   \n",
       "1         NaN        7471  10/26/15 12:40  6.587300e+17              NaN   \n",
       "2         NaN        5617  10/26/15 12:40  6.587300e+17           clcncl   \n",
       "3         NaN        1693  10/26/15 12:40  6.587300e+17    Palo Alto, CA   \n",
       "4         NaN       31462  10/26/15 12:40  6.587300e+17              NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                     Chennai  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2                    Belgrade  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"../gender-classifier-DFE-791531.csv\",encoding='latin1')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>815719226</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "      <td>sheezy0</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815719227</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>DavdBurnett</td>\n",
       "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>815719228</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "      <td>lwtprettylaugh</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>815719229</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>douggarland</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815719230</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>WilfordGemma</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  gender  gender:confidence  \\\n",
       "0  815719226    male             1.0000   \n",
       "1  815719227    male             1.0000   \n",
       "2  815719228    male             0.6625   \n",
       "3  815719229    male             1.0000   \n",
       "4  815719230  female             1.0000   \n",
       "\n",
       "                                         description            name  \\\n",
       "0                              i sing my own rhythm.         sheezy0   \n",
       "1  I'm the author of novels filled with family dr...     DavdBurnett   \n",
       "2                louis whining and squealing and all  lwtprettylaugh   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...     douggarland   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...    WilfordGemma   \n",
       "\n",
       "                                                text  \n",
       "0  Robbie E Responds To Critics After Win Against...  \n",
       "1  ÛÏIt felt like they were my friends and I was...  \n",
       "2  i absolutely adore when louis starts the songs...  \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...  \n",
       "4  Watching Neighbours on Sky+ catching up with t...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"gender-classifier-DFE-791531.csv\",encoding='latin1',usecols=[0,5,6,10,14,19])\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female     6700\n",
       "male       6194\n",
       "brand      5942\n",
       "unknown    1117\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata.description = metadata.description.fillna(' ')\n",
    "metadata.text = metadata.text.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL_PATTERN='(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$'\n",
    "# HASHTAG_PATTERN = '#\\w*'\n",
    "HASHTAG_PATTERN = '#'\n",
    "MENTION_PATTERN = '@\\w*'\n",
    "def cleantext (s):\n",
    "    s = re.sub(URL_PATTERN,' ',s)\n",
    "    s = re.sub(HASHTAG_PATTERN,' ',s)\n",
    "    s = re.sub(MENTION_PATTERN,' ',s)\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME_PATTERN = '[^a-zA-Z]'\n",
    "def cleanname(s):\n",
    "    s = re.sub(NAME_PATTERN,' ',s)\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['text_clean'] = [ cleantext(s) for s in metadata['text']]\n",
    "metadata['desc_clean'] = [s.lower() for s in metadata['description']]\n",
    "metadata['name_clean'] = [cleanname(s) for s in metadata['name']]\n",
    "data_gender = metadata.loc[metadata[\"gender\"].isin([\"female\",\"male\"])]\n",
    "data = data_gender.loc[data_gender[\"gender:confidence\"]>=0.6]\n",
    "data_unused = data_gender.loc[data_gender[\"gender:confidence\"]<0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29              RinCutie\n",
       "43         mrshoran_girl\n",
       "131             mirakyun\n",
       "238       AltarOfTheCowl\n",
       "251         TheBigBunBun\n",
       "319        guy_someone69\n",
       "427           rabah_wael\n",
       "520        Tangent_Grunt\n",
       "554        nouisftangels\n",
       "639          melodisthes\n",
       "676           babewharry\n",
       "734           sXeBatpunk\n",
       "813           CoolJazFae\n",
       "842       IncitatusSwift\n",
       "948           Paw_Online\n",
       "1013            icybomb_\n",
       "1107      OstapKohlstein\n",
       "1144      E_FillingaHole\n",
       "1158        wosolaurmani\n",
       "1178      IamSophieLee93\n",
       "1373            meirelav\n",
       "1402       KimberlyRules\n",
       "1428         dark_latara\n",
       "1437       andyhartleyuk\n",
       "1474             Emarged\n",
       "1497       andyhartleyuk\n",
       "1558        arachnocadia\n",
       "1574             mrk1xv1\n",
       "1733      ThirdEyeYoukai\n",
       "1741           KimoForce\n",
       "              ...       \n",
       "18902       BlackGtrQuen\n",
       "18993       TheHippyPaco\n",
       "19028           gjoveric\n",
       "19047      LoversLizquen\n",
       "19050    elizasoberano11\n",
       "19059           doolyprk\n",
       "19067            ZeboimG\n",
       "19069        sleighbells\n",
       "19081    AngeloIgnacio19\n",
       "19096        marion_cafc\n",
       "19214        potching666\n",
       "19295      hornyandhigh1\n",
       "19300      ImprobableJoe\n",
       "19341      xanderwonder2\n",
       "19385      wilie_pilapil\n",
       "19388     TheDazeyMayhem\n",
       "19427        FKittlerbot\n",
       "19450    TWENTY0NEPlLOTS\n",
       "19486          Missmmieh\n",
       "19519      COYGuerrillas\n",
       "19538        Ophiologist\n",
       "19586       SabriCancino\n",
       "19602       milknmuffins\n",
       "19722          94heskind\n",
       "19779     Sualte__Keoyfi\n",
       "19860    SaraContreras03\n",
       "19930          mariejois\n",
       "19935          hmuharold\n",
       "19976         briargilla\n",
       "20023      5yellowdogdem\n",
       "Name: name, Length: 401, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unused[\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=True,ngram_range=(1,2))\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57751938  0.56899225  0.61162791  0.62170543  0.613654    0.59425912\n",
      "  0.59813809  0.58727696  0.59115593  0.61675718]\n",
      "0.598108623354\n"
     ]
    }
   ],
   "source": [
    "## text feature\n",
    "x = vectorizer.fit_transform(data['text_clean'])\n",
    "y = encoder.fit_transform(data['gender'])\n",
    "\n",
    "nb = MultinomialNB()\n",
    "scores = cross_val_score(nb, x, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x87775 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64263566  0.64651163  0.67751938  0.6627907   0.64856478  0.65244375\n",
      "  0.66408068  0.64158262  0.65787432  0.66408068]\n",
      "0.655808420685\n"
     ]
    }
   ],
   "source": [
    "##description data\n",
    "x = vectorizer.fit_transform(data['desc_clean'])\n",
    "nb = MultinomialNB()\n",
    "scores = cross_val_score(nb, x, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenhu/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## combine all text features\n",
    "data[\"all_text\"] = data[['text_clean', 'desc_clean']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67674418604651165, 0.66899224806201552, 0.66511627906976745, 0.69147286821705423, 0.66356589147286826, 0.65658914728682172, 0.68604651162790697, 0.64806201550387599, 0.68527131782945738, 0.68837209302325586]\n",
      "0.673023255814\n",
      "0.730440189246\n",
      "0.50052288864\n",
      "0.0183439254761\n"
     ]
    }
   ],
   "source": [
    "##MultiNB\n",
    "x = vectorizer.fit_transform(data['all_text'])\n",
    "nb = MultinomialNB()\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    nb.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = nb.predict(x_test)\n",
    "    acc.append(nb.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67364341085271318, 0.68062015503875972, 0.67829457364341084, 0.67209302325581399, 0.65736434108527131, 0.67441860465116277, 0.67596899224806206, 0.67829457364341084, 0.69844961240310077, 0.66821705426356592]\n",
      "0.675736434109\n",
      "0.672759215626\n",
      "0.626480104286\n",
      "19.8468978405\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "clf = svm.SVC(kernel = pairwise.cosine_similarity,probability = True)\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = clf.predict(x_test)\n",
    "    acc.append(clf.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67829457364341084, 0.66356589147286826, 0.66744186046511633, 0.68139534883720931, 0.68217054263565891, 0.66744186046511633, 0.65503875968992253, 0.69379844961240311, 0.67441860465116277, 0.66976744186046511]\n",
      "0.673333333333\n",
      "0.681525830055\n",
      "0.608488560736\n",
      "0.162819862366\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = clf.predict(x_test)\n",
    "    acc.append(clf.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': None, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gridsearch best params for Logistic\n",
    "param = {\"C\":(0.1,0.3,0.4,0.5,0.6,0.8,1),\"penalty\":(\"l1\",\"l2\"),\"class_weight\":(None,\"balanced\")}\n",
    "model = LogisticRegression()\n",
    "clf = GridSearchCV(model,param)\n",
    "clf.fit(x,y)\n",
    "bestparam = clf.best_params_ \n",
    "bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68449612403100779, 0.66124031007751938, 0.68372093023255809, 0.69999999999999996, 0.68682170542635657, 0.66899224806201552, 0.67441860465116277, 0.65116279069767447, 0.6953488372093023, 0.68682170542635657]\n",
      "0.679302325581\n",
      "0.693054092665\n",
      "0.608210997757\n",
      "0.20526099205\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1,penalty='l2')\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = clf.predict(x_test)\n",
    "    acc.append(clf.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_b = CountVectorizer(stop_words='english',lowercase=True,ngram_range=(1,2),binary=True)\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67829457364341084, 0.67364341085271318, 0.67131782945736429, 0.66976744186046511, 0.66589147286821704, 0.65581395348837213, 0.68139534883720931, 0.68837209302325586, 0.67674418604651165, 0.69922480620155036]\n",
      "0.676046511628\n",
      "0.694610105188\n",
      "0.580999420282\n",
      "0.0132629871368\n"
     ]
    }
   ],
   "source": [
    "x = vectorizer_b.fit_transform(data['all_text'])\n",
    "nb = MultinomialNB()\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    nb.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = nb.predict(x_test)\n",
    "    acc.append(nb.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try char n grams on name_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_char = CountVectorizer(analyzer='char_wb',lowercase=True,ngram_range=(1,5),binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70387596899224802, 0.73875968992248064, 0.71240310077519375, 0.7441860465116279, 0.70852713178294568, 0.73255813953488369, 0.69379844961240311, 0.72480620155038755, 0.73023255813953492, 0.70852713178294568]\n",
      "0.71976744186\n",
      "0.700003016851\n",
      "0.717587022986\n",
      "0.0133628845215\n"
     ]
    }
   ],
   "source": [
    "x = vectorizer_char.fit_transform(data['name_clean'])\n",
    "y = encoder.fit_transform(data['gender'])\n",
    "nb = MultinomialNB()\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    nb.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = nb.predict(x_test)\n",
    "    acc.append(nb.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_char = CountVectorizer(analyzer='char_wb',lowercase=True,ngram_range=(1,5),binary=True,max_features = 5000)\n",
    "x = vectorizer_char.fit_transform(data['all_text'])\n",
    "y = encoder.fit_transform(data['gender'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "len(vectorizer_char.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# name_clean using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52015503875968994"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=0.001, hidden_layer_sizes=(500,100,2))\n",
    "clf.fit(x_train,y_train)\n",
    "ypred = clf.predict(x_test)\n",
    "testacc = accuracy_score(y_test,ypred)\n",
    "testacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64496124031007751"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "ypred = clf.predict(x_test)\n",
    "testacc = accuracy_score(y_test,ypred)\n",
    "testacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# name_clean using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70310077519379843, 0.69922480620155036, 0.67674418604651165, 0.70310077519379843, 0.71240310077519375, 0.68527131782945738, 0.70542635658914732, 0.71472868217054264, 0.69844961240310077, 0.70387596899224802]\n",
      "0.70023255814\n",
      "0.671004562035\n",
      "0.716461867812\n",
      "18.5693640709\n"
     ]
    }
   ],
   "source": [
    "x =  vectorizer_char.fit_transform(data['name_clean'])\n",
    "clf = svm.SVC(kernel = pairwise.cosine_similarity,probability = True)\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = clf.predict(x_test)\n",
    "    acc.append(clf.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging name, desc, twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_char = CountVectorizer(analyzer='char_wb',lowercase=True,ngram_range=(1,5),binary=True)\n",
    "X_name = vectorizer_char.fit_transform(data['name_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word = TfidfVectorizer(stop_words='english',lowercase=True,ngram_range=(1,2),binary=True)\n",
    "X_alltext = vectorizer_word.fit_transform(data['all_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = hstack((X_name, X_alltext))\n",
    "y = encoder.fit_transform(data['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73255813953488369, 0.70852713178294568, 0.74108527131782942, 0.73023255813953492, 0.74108527131782942, 0.7317829457364341, 0.72635658914728685, 0.71317829457364346, 0.72093023255813948, 0.73565891472868217]\n",
      "0.728139534884\n",
      "0.739004437544\n",
      "0.677307350564\n",
      "0.0237159729004\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_all, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    nb.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = nb.predict(x_test)\n",
    "    acc.append(nb.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.4, 'fit_prior': False}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha':(0.1,0.4,0.45,0.5,2,5),'fit_prior':(True,False)}\n",
    "model = MultinomialNB()\n",
    "clf = GridSearchCV(model,params)\n",
    "clf.fit(X_all,y)\n",
    "bestparam = clf.best_params_ \n",
    "bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72868217054263562, 0.72248062015503878, 0.73488372093023258, 0.72635658914728685, 0.74108527131782942, 0.72325581395348837, 0.73643410852713176, 0.73410852713178298, 0.72325581395348837, 0.72248062015503878]\n",
      "0.729302325581\n",
      "0.723001731964\n",
      "0.715698860833\n",
      "0.0210030078888\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.4,fit_prior=False)\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_all, y, test_size=0.1)\n",
    "    start =time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = model.predict(x_test)\n",
    "    acc.append(model.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add unused data to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.4, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = MultinomialNB(alpha=0.4,fit_prior=False)\n",
    "model_best.fit(X_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenhu/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_unused['all_text'] = data_unused[['text_clean', 'desc_clean']].apply(lambda x: ' '.join(x), axis=1)\n",
    "Xtest_name = vectorizer_char.transform(data_unused['name_clean'])\n",
    "Xtest_text = vectorizer_word.transform(data_unused['all_text'])\n",
    "Xtest_all = hstack((Xtest_name, Xtest_text))\n",
    "ytest = encoder.transform(data_unused['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_pred = model_best.predict(Xtest_all)\n",
    "ytest_pred,ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_unused[ytest_pred == ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12710"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_addnew = data_unused[ytest_pred == ytest]\n",
    "data_final = pd.concat([data,data_addnew])\n",
    "len(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.3, 'fit_prior': False}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfinal_name = vectorizer_char.fit_transform(data_final['name_clean'])\n",
    "Xfinal_text = vectorizer_word.fit_transform(data_final['all_text'])\n",
    "Xfinal_all = hstack((Xfinal_name, Xfinal_text))\n",
    "yfinal = encoder.fit_transform(data_final['gender'])\n",
    "\n",
    "params = {'alpha':(0.1,0.3,0.5,1,2,5),'fit_prior':(True,False)}\n",
    "model_temp = MultinomialNB()\n",
    "clf = GridSearchCV(model,params)\n",
    "clf.fit(Xfinal_all,yfinal)\n",
    "bestparam = clf.best_params_ \n",
    "bestparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75059008654602677, 0.72069236821400473, 0.73485444531864674, 0.7301337529504327, 0.73800157356412277, 0.73485444531864674, 0.71439811172305268, 0.73170731707317072, 0.75688434303697871, 0.73170731707317072]\n",
      "0.734382376082\n",
      "0.723157880445\n",
      "0.721154315325\n",
      "0.0209639072418\n"
     ]
    }
   ],
   "source": [
    "model_text_final = MultinomialNB(alpha=0.3)\n",
    "acc = []\n",
    "pre = []\n",
    "recall = []\n",
    "duration =[]\n",
    "for i in range(10):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(Xfinal_all, yfinal, test_size=0.1)\n",
    "    start =time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end = time.time()\n",
    "    duration.append(end-start)\n",
    "    ypred = model.predict(x_test)\n",
    "    acc.append(model.score(x_test, y_test))\n",
    "    pre.append(precision_score(y_test,ypred))\n",
    "    recall.append(recall_score(y_test,ypred))\n",
    "\n",
    "print(acc)\n",
    "print(np.mean(acc))\n",
    "print(np.mean(pre))\n",
    "print(np.mean(recall))\n",
    "print(duration[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_text_final, open( \"text_multinb.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenchenhu/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/chenchenhu/anaconda/lib/python2.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.0 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_model = pickle.load( open( \"random_forest.pkl\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
